{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e83af044",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imporating libraries\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89ac093b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_text</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>review_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>e8cb23191d6c27e930243a08ff826395</th>\n",
       "      <td>realli meant get landlin check one reason coul...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>953dfd48b372f081b5f82ce1def753f7</th>\n",
       "      <td>updat make maximum ride movi look terribl http...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48509a6f6128d4f2ca243e04a0cdc896</th>\n",
       "      <td>feel like ive read mani urban fantasi book get...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a09f7ff4eca0c8c2fbaacf4baf6b114f</th>\n",
       "      <td>reread decemb simpli fantast read full humor m...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93b0128f768ee9c1af8864f566e3a7b6</th>\n",
       "      <td>big ass dnf ughhh im mad pick even care book o...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                        review_text  \\\n",
       "review_id                                                                             \n",
       "e8cb23191d6c27e930243a08ff826395  realli meant get landlin check one reason coul...   \n",
       "953dfd48b372f081b5f82ce1def753f7  updat make maximum ride movi look terribl http...   \n",
       "48509a6f6128d4f2ca243e04a0cdc896  feel like ive read mani urban fantasi book get...   \n",
       "a09f7ff4eca0c8c2fbaacf4baf6b114f  reread decemb simpli fantast read full humor m...   \n",
       "93b0128f768ee9c1af8864f566e3a7b6  big ass dnf ughhh im mad pick even care book o...   \n",
       "\n",
       "                                  rating  \n",
       "review_id                                 \n",
       "e8cb23191d6c27e930243a08ff826395       4  \n",
       "953dfd48b372f081b5f82ce1def753f7       4  \n",
       "48509a6f6128d4f2ca243e04a0cdc896       3  \n",
       "a09f7ff4eca0c8c2fbaacf4baf6b114f       5  \n",
       "93b0128f768ee9c1af8864f566e3a7b6       1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('cleaned_train.csv',header=0,index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "05d58aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use only a small subset of records for testing (e.g., first 1000 records)\n",
    "df_subset = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4542f1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into features (X) and target (y)\n",
    "X = df_subset['review_text']\n",
    "y = df_subset['rating']\n",
    "#here done for the subset only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fcdf11f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the rating to integers (if it's not already)\n",
    "y = y.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e439b728",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missing values in 'review_text' for both training and testing sets\n",
    "df_subset['review_text'].fillna('', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "499da1e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 504000\n",
      "Testing set size: 126000\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Print the sizes of the training and testing sets\n",
    "print(\"Training set size:\", len(X_train))\n",
    "print(\"Testing set size:\", len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d44b8cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize the text data using TF-IDF\n",
    "vectorizer = TfidfVectorizer(max_features=500)  # Adjust max_features as needed\n",
    "X_train_vectorized = vectorizer.fit_transform(X_train)\n",
    "X_test_vectorized = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a907a201",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the TF-IDF vectors\n",
    "scaler = StandardScaler(with_mean=False)  # Sparse matrix, so use with_mean=False\n",
    "X_train_scaled = scaler.fit_transform(X_train_vectorized)\n",
    "X_test_scaled = scaler.transform(X_test_vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ead5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'kernel': ['linear', 'rbf', 'poly'],\n",
    "    'C': [0.1, 1, 10],\n",
    "    'gamma': ['auto', 'scale', 0.1, 1],\n",
    "    'degree': [2, 3, 4]\n",
    "}\n",
    "\n",
    "# Create an SVM classifier\n",
    "svm_model = SVC()\n",
    "\n",
    "# Perform Grid Search with cross-validation\n",
    "grid_search = GridSearchCV(svm_model, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Get the best parameters\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best Hyperparameters:\", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9860c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the best model for predictions\n",
    "best_model = grid_search.best_estimator_\n",
    "#X_test_vectorized = vectorizer.transform(X_test)\n",
    "\n",
    "y_pred = best_model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0813eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Build and train an SVM model (SVC for classification)\n",
    "# svm_model = SVC(C=2, max_iter=100, kernel='linear') \n",
    "# svm_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# # Make predictions on the test set\n",
    "# y_pred = model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244dcca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the best model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8632687",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print classification report\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4db4b23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\acer\\anaconda3\\envs\\nlp_course\\python.exe\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "print(sys.executable)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2b4a49",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
