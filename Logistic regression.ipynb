{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f7eae1c",
   "metadata": {},
   "source": [
    "# Logistic Regression Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c69805c",
   "metadata": {},
   "source": [
    "This notebook focuses on training a logistic regression model using the provided dataset. \n",
    "Logistic regression is a widely used classification algorithm suitable for binary and multiclass classification tasks. \n",
    "The goal is to create and train a logistic regression model to predict target labels based on the input features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a8d212c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing required libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c370a77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_text</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>review_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>e8cb23191d6c27e930243a08ff826395</th>\n",
       "      <td>realli meant get landlin check one reason coul...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>953dfd48b372f081b5f82ce1def753f7</th>\n",
       "      <td>updat make maximum ride movi look terribl http...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48509a6f6128d4f2ca243e04a0cdc896</th>\n",
       "      <td>feel like ive read mani urban fantasi book get...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a09f7ff4eca0c8c2fbaacf4baf6b114f</th>\n",
       "      <td>reread decemb simpli fantast read full humor m...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93b0128f768ee9c1af8864f566e3a7b6</th>\n",
       "      <td>big ass dnf ughhh im mad pick even care book o...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                        review_text  \\\n",
       "review_id                                                                             \n",
       "e8cb23191d6c27e930243a08ff826395  realli meant get landlin check one reason coul...   \n",
       "953dfd48b372f081b5f82ce1def753f7  updat make maximum ride movi look terribl http...   \n",
       "48509a6f6128d4f2ca243e04a0cdc896  feel like ive read mani urban fantasi book get...   \n",
       "a09f7ff4eca0c8c2fbaacf4baf6b114f  reread decemb simpli fantast read full humor m...   \n",
       "93b0128f768ee9c1af8864f566e3a7b6  big ass dnf ughhh im mad pick even care book o...   \n",
       "\n",
       "                                  rating  \n",
       "review_id                                 \n",
       "e8cb23191d6c27e930243a08ff826395       4  \n",
       "953dfd48b372f081b5f82ce1def753f7       4  \n",
       "48509a6f6128d4f2ca243e04a0cdc896       3  \n",
       "a09f7ff4eca0c8c2fbaacf4baf6b114f       5  \n",
       "93b0128f768ee9c1af8864f566e3a7b6       1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load your dataset\n",
    "df = pd.read_csv('cleaned_train.csv',header=0,index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e516235",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subset = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "770e4e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missing values in 'review_text' for both training and testing sets\n",
    "df_subset['review_text'].fillna('', inplace=True)\n",
    "\n",
    "# Split the data into features (X) and target (y)\n",
    "X = df_subset['review_text']\n",
    "y = df_subset['rating']  # Assuming 'rating' is an integer between 0 and 5\n",
    "\n",
    "# Convert the rating to integers (if it's not already)\n",
    "y = y.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e75e249",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 504000\n",
      "Testing set size: 126000\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Explicitly handle missing values in 'review_text' for both training and testing sets\n",
    "X_train = X_train.fillna('')\n",
    "X_test = X_test.fillna('')\n",
    "\n",
    "# Print the sizes of the training and testing sets\n",
    "print(\"Training set size:\", len(X_train))\n",
    "print(\"Testing set size:\", len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7044f415",
   "metadata": {},
   "source": [
    "## Vectorization \n",
    "In this section, we focus on transforming textual data into a format suitable for machine learning models. \n",
    "The chosen technique is Term Frequency-Inverse Document Frequency (TF-IDF), a widely used method for converting text data \n",
    "into numerical vectors while considering the importance of words within a document and across the entire dataset.\n",
    "\n",
    "The `TfidfVectorizer` from the Scikit-learn library is employed to perform TF-IDF vectorization on the text data. \n",
    "The `max_features` parameter is adjustable to control the maximum number of features (terms) retained in the vectorized representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d18b5c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X_train_vectorized = vectorizer.fit_transform(X_train)\n",
    "X_test_vectorized = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3440ec39",
   "metadata": {},
   "source": [
    "# Scale the TF-IDF vectors\n",
    "scaler = StandardScaler(with_mean=False)  # Sparse matrix, so use with_mean=False\n",
    "X_train_scaled = scaler.fit_transform(X_train_vectorized)\n",
    "X_test_scaled = scaler.transform(X_test_vectorized)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5994396c",
   "metadata": {},
   "source": [
    "## Model Training\n",
    "This cell focuses on building and training a Logistic Regression model using the TF-IDF vectorized text data. Logistic \n",
    "\n",
    "- **C (Regularization Parameter):** Set to 2 for regularization control.\n",
    "- **Max Iterations:** Limited to 1000 iterations during training.\n",
    "- **n_jobs:** Utilizes all available CPU cores for parallel computation.\n",
    "\n",
    "The Logistic Regression model is trained on the TF-IDF vectorized training data (`X_train_vectorized`) with corresponding labels (`y_train`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "49552cc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=2, max_iter=1000, n_jobs=-1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=2, max_iter=1000, n_jobs=-1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(C=2, max_iter=1000, n_jobs=-1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build and train a Logistic Regression model\n",
    "lr = LogisticRegression(C= 2, max_iter = 1000, n_jobs=-1)  # You can experiment with different parameters\n",
    "lr.fit(X_train_vectorized, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad76b7d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5233968253968254\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.28      0.36      4327\n",
      "           1       0.46      0.29      0.36      4035\n",
      "           2       0.42      0.28      0.34     10187\n",
      "           3       0.46      0.41      0.44     26590\n",
      "           4       0.49      0.61      0.54     43754\n",
      "           5       0.63      0.63      0.63     37107\n",
      "\n",
      "    accuracy                           0.52    126000\n",
      "   macro avg       0.50      0.42      0.44    126000\n",
      "weighted avg       0.52      0.52      0.52    126000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test set\n",
    "y_pred = lr.predict(X_test_vectorized)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "683a4f08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tfidf_vectorizer_v3.joblib']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#saving The vectorizer and the trained model\n",
    "joblib.dump(lr, 'logistic_regression_model_v3.joblib')\n",
    "joblib.dump(vectorizer, 'tfidf_vectorizer_v3.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "089d37bc",
   "metadata": {},
   "source": [
    "# END"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb5a1100",
   "metadata": {},
   "source": [
    "The below cell was used during Development to fine tune the hyperparameters."
   ]
  },
  {
   "cell_type": "raw",
   "id": "2aed8cda",
   "metadata": {},
   "source": [
    "#Use of hyper parameter tuning\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# Build and train a Logistic Regression model with hyperparameter tuning\n",
    "param_grid = {\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100],  # Adjust the range based on your preference\n",
    "    'max_iter': [50, 100, 200, 500]  # Adjust the range based on your preference\n",
    "}\n",
    "\n",
    "# Create a logistic regression model\n",
    "lr = LogisticRegression(n_jobs=-1)\n",
    "\n",
    "# Use GridSearchCV for hyperparameter tuning\n",
    "grid_search = GridSearchCV(lr, param_grid, cv=5, scoring='accuracy')  # Adjust the scoring metric as needed\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "\n",
    "# Evaluate the model on the test set using the best hyperparameters\n",
    "best_lr = grid_search.best_estimator_\n",
    "accuracy = best_lr.score(X_test_scaled, y_test)\n",
    "print(\"Accuracy on Test Set:\", accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
